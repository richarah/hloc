{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperGlue Feature Matching Demo\n",
    "\n",
    "This notebook demonstrates SuperGlue feature matching using video input from the videos directory. It shows:\n",
    "- Real-time feature detection with SuperPoint\n",
    "- Feature matching with SuperGlue (including Sinkhorn algorithm)\n",
    "- Visualization of keypoints and matches\n",
    "- Interactive parameter tuning\n",
    "- Performance analysis and statistics\n",
    "\n",
    "Based on the SuperGlue implementation from Magic Leap's pretrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Add SuperGlue path\n",
    "superglue_path = '../modules/hloc/third_party/SuperGluePretrainedNetwork'\n",
    "sys.path.append(superglue_path)\n",
    "\n",
    "from models.matching import Matching\n",
    "from models.utils import AverageTimer, VideoStreamer, make_matching_plot_fast, frame2tensor\n",
    "\n",
    "# Disable gradients for inference\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print(\"SuperGlue Demo Environment Setup Complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure SuperGlue parameters including the Sinkhorn algorithm iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_DIR = Path(\"../videos\")\n",
    "OUTPUT_DIR = Path(\"../outputs/superglue_demo\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SuperGlue configuration\n",
    "config = {\n",
    "    'superpoint': {\n",
    "        'nms_radius': 4,\n",
    "        'keypoint_threshold': 0.005,\n",
    "        'max_keypoints': 1024\n",
    "    },\n",
    "    'superglue': {\n",
    "        'weights': 'outdoor',  # 'indoor' or 'outdoor'\n",
    "        'sinkhorn_iterations': 20,  # Number of Sinkhorn iterations (key parameter!)\n",
    "        'match_threshold': 0.2,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Processing parameters\n",
    "RESIZE = [640, 480]  # [width, height]\n",
    "SKIP_FRAMES = 1      # Process every N-th frame\n",
    "MAX_FRAMES = 200     # Maximum frames to process (None for all)\n",
    "SAVE_MATCHES = True  # Save matching visualizations\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Running inference on device: {device}\")\n",
    "print(f\"Configuration: {config}\")\n",
    "print(f\"Sinkhorn iterations: {config['superglue']['sinkhorn_iterations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Video Input\n",
    "\n",
    "Load and preview video files from the videos directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available videos\n",
    "video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}\n",
    "available_videos = []\n",
    "\n",
    "if INPUT_DIR.exists():\n",
    "    for file_path in INPUT_DIR.iterdir():\n",
    "        if file_path.is_file() and file_path.suffix.lower() in video_extensions:\n",
    "            available_videos.append(file_path)\n",
    "\n",
    "print(f\"Found {len(available_videos)} video files:\")\n",
    "for i, video in enumerate(available_videos):\n",
    "    print(f\"  {i}: {video.name}\")\n",
    "\n",
    "if not available_videos:\n",
    "    print(\"No videos found! Please add video files to the videos/ directory.\")\n",
    "    print(f\"Supported formats: {', '.join(video_extensions)}\")\n",
    "else:\n",
    "    # Select first video by default\n",
    "    selected_video = available_videos[0]\n",
    "    print(f\"\\nSelected video: {selected_video.name}\")\n",
    "    \n",
    "    # Get video info\n",
    "    cap = cv2.VideoCapture(str(selected_video))\n",
    "    if cap.isOpened():\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        duration = frame_count / fps if fps > 0 else 0\n",
    "        \n",
    "        print(f\"Video info:\")\n",
    "        print(f\"  Resolution: {width}x{height}\")\n",
    "        print(f\"  FPS: {fps:.2f}\")\n",
    "        print(f\"  Frames: {frame_count}\")\n",
    "        print(f\"  Duration: {duration:.2f} seconds\")\n",
    "        \n",
    "        # Show first frame\n",
    "        ret, first_frame = cap.read()\n",
    "        if ret:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f\"First frame from {selected_video.name}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"Error: Could not open video {selected_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SuperGlue Matcher\n",
    "\n",
    "Initialize the SuperGlue matching system with SuperPoint feature detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if available_videos:\n",
    "    # Initialize SuperGlue matching pipeline\n",
    "    print(\"Initializing SuperGlue matcher...\")\n",
    "    matching = Matching(config).eval().to(device)\n",
    "    keys = ['keypoints', 'scores', 'descriptors']\n",
    "    \n",
    "    print(f\"SuperGlue model loaded successfully!\")\n",
    "    print(f\"Model configuration:\")\n",
    "    print(f\"  SuperPoint config: {matching.superpoint.config}\")\n",
    "    print(f\"  SuperGlue config: {matching.superglue.config}\")\n",
    "    print(f\"  Sinkhorn iterations: {matching.superglue.config['sinkhorn_iterations']}\")\n",
    "    \n",
    "    # Initialize video streamer\n",
    "    vs = VideoStreamer(str(selected_video), RESIZE, SKIP_FRAMES, max_length=MAX_FRAMES)\n",
    "    \n",
    "    # Process first frame to initialize\n",
    "    frame, ret = vs.next_frame()\n",
    "    if ret:\n",
    "        print(f\"Video streamer initialized. Frame shape: {frame.shape}\")\n",
    "        \n",
    "        # Convert to tensor and extract features\n",
    "        frame_tensor = frame2tensor(frame, device)\n",
    "        last_data = matching.superpoint({'image': frame_tensor})\n",
    "        last_data = {k+'0': last_data[k] for k in keys}\n",
    "        last_data['image0'] = frame_tensor\n",
    "        last_frame = frame\n",
    "        last_frame_id = 0\n",
    "        \n",
    "        print(f\"First frame processed:\")\n",
    "        print(f\"  Keypoints detected: {len(last_data['keypoints0'][0])}\")\n",
    "        print(f\"  Descriptor shape: {last_data['descriptors0'].shape}\")\n",
    "        \n",
    "        # Visualize first frame keypoints\n",
    "        kpts = last_data['keypoints0'][0].cpu().numpy()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.scatter(kpts[:, 0], kpts[:, 1], c='red', s=2, alpha=0.7)\n",
    "        plt.title(f\"SuperPoint keypoints on first frame ({len(kpts)} points)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Could not read first frame from video\")\n",
    "else:\n",
    "    print(\"Skipping SuperGlue initialization - no videos available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperGlue Feature Matching Demo\n",
    "\n",
    "Process video frames and demonstrate SuperGlue feature matching with Sinkhorn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if available_videos and 'last_data' in locals():\n",
    "    print(\"Starting SuperGlue feature matching demo...\")\n",
    "    \n",
    "    # Initialize statistics tracking\n",
    "    timer = AverageTimer()\n",
    "    match_stats = {\n",
    "        'frame_pairs': [],\n",
    "        'keypoints_0': [],\n",
    "        'keypoints_1': [],\n",
    "        'matches_count': [],\n",
    "        'match_scores': [],\n",
    "        'processing_times': [],\n",
    "        'sinkhorn_iterations': []\n",
    "    }\n",
    "    \n",
    "    processed_frames = 0\n",
    "    visualization_frames = []\n",
    "    \n",
    "    print(f\"Processing up to {MAX_FRAMES if MAX_FRAMES else 'all'} frames...\")\n",
    "    \n",
    "    while processed_frames < (MAX_FRAMES or float('inf')):\n",
    "        frame, ret = vs.next_frame()\n",
    "        if not ret:\n",
    "            print(\"End of video reached\")\n",
    "            break\n",
    "            \n",
    "        timer.update('data')\n",
    "        current_frame_id = vs.i - 1\n",
    "        \n",
    "        # Convert frame to tensor and run SuperGlue\n",
    "        frame_tensor = frame2tensor(frame, device)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        pred = matching({**last_data, 'image1': frame_tensor})\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Extract results\n",
    "        kpts0 = last_data['keypoints0'][0].cpu().numpy()\n",
    "        kpts1 = pred['keypoints1'][0].cpu().numpy()\n",
    "        matches = pred['matches0'][0].cpu().numpy()\n",
    "        confidence = pred['matching_scores0'][0].cpu().numpy()\n",
    "        \n",
    "        timer.update('forward')\n",
    "        \n",
    "        # Calculate matches\n",
    "        valid = matches > -1\n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches[valid]]\n",
    "        match_confidence = confidence[valid]\n",
    "        \n",
    "        # Store statistics\n",
    "        match_stats['frame_pairs'].append((last_frame_id, current_frame_id))\n",
    "        match_stats['keypoints_0'].append(len(kpts0))\n",
    "        match_stats['keypoints_1'].append(len(kpts1))\n",
    "        match_stats['matches_count'].append(len(mkpts0))\n",
    "        match_stats['match_scores'].append(match_confidence.mean() if len(match_confidence) > 0 else 0)\n",
    "        match_stats['processing_times'].append(processing_time)\n",
    "        match_stats['sinkhorn_iterations'].append(config['superglue']['sinkhorn_iterations'])\n",
    "        \n",
    "        # Create visualization\n",
    "        color = cm.jet(match_confidence) if len(match_confidence) > 0 else []\n",
    "        text = [\n",
    "            'SuperGlue Demo',\n",
    "            f'Keypoints: {len(kpts0)}:{len(kpts1)}',\n",
    "            f'Matches: {len(mkpts0)}'\n",
    "        ]\n",
    "        small_text = [\n",
    "            f'Sinkhorn iterations: {config[\"superglue\"][\"sinkhorn_iterations\"]}',\n",
    "            f'Match threshold: {config[\"superglue\"][\"match_threshold\"]}',\n",
    "            f'Frame pair: {last_frame_id:03d}:{current_frame_id:03d}',\n",
    "            f'Processing: {processing_time*1000:.1f}ms'\n",
    "        ]\n",
    "        \n",
    "        out = make_matching_plot_fast(\n",
    "            last_frame, frame, kpts0, kpts1, mkpts0, mkpts1, color, text,\n",
    "            path=None, show_keypoints=True, small_text=small_text\n",
    "        )\n",
    "        \n",
    "        # Save every 10th frame for visualization\n",
    "        if processed_frames % 10 == 0:\n",
    "            visualization_frames.append((out, current_frame_id, len(mkpts0)))\n",
    "        \n",
    "        # Save output if requested\n",
    "        if SAVE_MATCHES and processed_frames < 20:  # Save first 20 for demo\n",
    "            output_file = OUTPUT_DIR / f\"match_{last_frame_id:03d}_{current_frame_id:03d}.png\"\n",
    "            cv2.imwrite(str(output_file), out)\n",
    "        \n",
    "        timer.update('viz')\n",
    "        \n",
    "        # Progress update\n",
    "        if processed_frames % 20 == 0:\n",
    "            print(f\"Processed {processed_frames} frames - Matches: {len(mkpts0)} - Time: {processing_time*1000:.1f}ms\")\n",
    "        \n",
    "        processed_frames += 1\n",
    "    \n",
    "    vs.cleanup()\n",
    "    print(f\"\\nCompleted processing {processed_frames} frames!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping demo - no video or initialization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Results\n",
    "\n",
    "Display sample matching results and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'visualization_frames' in locals() and len(visualization_frames) > 0:\n",
    "    print(f\"Displaying {len(visualization_frames)} sample matching results:\")\n",
    "    \n",
    "    # Show first few matching results\n",
    "    num_display = min(4, len(visualization_frames))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_display, 1, figsize=(15, 5*num_display))\n",
    "    if num_display == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(num_display):\n",
    "        out, frame_id, match_count = visualization_frames[i]\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        out_rgb = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[i].imshow(out_rgb)\n",
    "        axes[i].set_title(f\"Frame {frame_id}: {match_count} matches\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No visualization frames available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze SuperGlue performance and the impact of Sinkhorn iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'match_stats' in locals() and len(match_stats['matches_count']) > 0:\n",
    "    print(\"SuperGlue Performance Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_frames = len(match_stats['matches_count'])\n",
    "    avg_keypoints_0 = np.mean(match_stats['keypoints_0'])\n",
    "    avg_keypoints_1 = np.mean(match_stats['keypoints_1'])\n",
    "    avg_matches = np.mean(match_stats['matches_count'])\n",
    "    avg_match_score = np.mean([s for s in match_stats['match_scores'] if s > 0])\n",
    "    avg_processing_time = np.mean(match_stats['processing_times'])\n",
    "    fps = 1.0 / avg_processing_time if avg_processing_time > 0 else 0\n",
    "    \n",
    "    print(f\"Processed frames: {total_frames}\")\n",
    "    print(f\"Average keypoints per frame: {avg_keypoints_0:.1f} / {avg_keypoints_1:.1f}\")\n",
    "    print(f\"Average matches per frame: {avg_matches:.1f}\")\n",
    "    print(f\"Average match score: {avg_match_score:.3f}\")\n",
    "    print(f\"Average processing time: {avg_processing_time*1000:.1f}ms\")\n",
    "    print(f\"Processing FPS: {fps:.1f}\")\n",
    "    print(f\"Sinkhorn iterations used: {config['superglue']['sinkhorn_iterations']}\")\n",
    "    \n",
    "    # Matching efficiency\n",
    "    match_ratios = [m/(k0+k1) if (k0+k1) > 0 else 0 \n",
    "                   for m, k0, k1 in zip(match_stats['matches_count'], \n",
    "                                       match_stats['keypoints_0'], \n",
    "                                       match_stats['keypoints_1'])]\n",
    "    avg_match_ratio = np.mean(match_ratios)\n",
    "    print(f\"Average match ratio: {avg_match_ratio:.3f} (matches / total keypoints)\")\n",
    "    \n",
    "    # Create performance plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Matches over time\n",
    "    axes[0, 0].plot(match_stats['matches_count'], 'b-', alpha=0.7)\n",
    "    axes[0, 0].axhline(y=avg_matches, color='r', linestyle='--', label=f'Avg: {avg_matches:.1f}')\n",
    "    axes[0, 0].set_title('Matches per Frame')\n",
    "    axes[0, 0].set_xlabel('Frame')\n",
    "    axes[0, 0].set_ylabel('Number of Matches')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Processing time over time\n",
    "    processing_times_ms = [t*1000 for t in match_stats['processing_times']]\n",
    "    axes[0, 1].plot(processing_times_ms, 'g-', alpha=0.7)\n",
    "    axes[0, 1].axhline(y=avg_processing_time*1000, color='r', linestyle='--', \n",
    "                      label=f'Avg: {avg_processing_time*1000:.1f}ms')\n",
    "    axes[0, 1].set_title('Processing Time per Frame')\n",
    "    axes[0, 1].set_xlabel('Frame')\n",
    "    axes[0, 1].set_ylabel('Time (ms)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Keypoints distribution\n",
    "    axes[1, 0].hist(match_stats['keypoints_0'], bins=20, alpha=0.7, label='Frame 0', color='blue')\n",
    "    axes[1, 0].hist(match_stats['keypoints_1'], bins=20, alpha=0.7, label='Frame 1', color='orange')\n",
    "    axes[1, 0].set_title('Keypoints Distribution')\n",
    "    axes[1, 0].set_xlabel('Number of Keypoints')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Match scores distribution\n",
    "    valid_scores = [s for s in match_stats['match_scores'] if s > 0]\n",
    "    if valid_scores:\n",
    "        axes[1, 1].hist(valid_scores, bins=20, alpha=0.7, color='purple')\n",
    "        axes[1, 1].set_title('Match Confidence Distribution')\n",
    "        axes[1, 1].set_xlabel('Average Match Score')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No performance data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn Algorithm Analysis\n",
    "\n",
    "Analyze the impact of different Sinkhorn iteration counts on matching performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if available_videos and 'last_data' in locals():\n",
    "    print(\"Analyzing Sinkhorn Algorithm Impact\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test different Sinkhorn iteration counts\n",
    "    sinkhorn_test_values = [5, 10, 20, 50, 100]\n",
    "    sinkhorn_results = []\n",
    "    \n",
    "    # Reset video to beginning for consistent testing\n",
    "    vs_test = VideoStreamer(str(selected_video), RESIZE, SKIP_FRAMES, max_length=10)\n",
    "    test_frame1, _ = vs_test.next_frame()\n",
    "    test_frame2, _ = vs_test.next_frame()\n",
    "    \n",
    "    if test_frame1 is not None and test_frame2 is not None:\n",
    "        test_tensor1 = frame2tensor(test_frame1, device)\n",
    "        test_tensor2 = frame2tensor(test_frame2, device)\n",
    "        \n",
    "        print(\"Testing different Sinkhorn iteration counts...\")\n",
    "        \n",
    "        for sinkhorn_iters in sinkhorn_test_values:\n",
    "            print(f\"Testing {sinkhorn_iters} iterations...\")\n",
    "            \n",
    "            # Create new config with different Sinkhorn iterations\n",
    "            test_config = config.copy()\n",
    "            test_config['superglue']['sinkhorn_iterations'] = sinkhorn_iters\n",
    "            \n",
    "            # Initialize new matcher\n",
    "            test_matching = Matching(test_config).eval().to(device)\n",
    "            \n",
    "            # Extract features for first frame\n",
    "            test_data1 = test_matching.superpoint({'image': test_tensor1})\n",
    "            test_data1 = {k+'0': test_data1[k] for k in keys}\n",
    "            test_data1['image0'] = test_tensor1\n",
    "            \n",
    "            # Measure performance\n",
    "            start_time = time.time()\n",
    "            pred = test_matching({**test_data1, 'image1': test_tensor2})\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Calculate results\n",
    "            kpts0 = test_data1['keypoints0'][0].cpu().numpy()\n",
    "            kpts1 = pred['keypoints1'][0].cpu().numpy()\n",
    "            matches = pred['matches0'][0].cpu().numpy()\n",
    "            confidence = pred['matching_scores0'][0].cpu().numpy()\n",
    "            \n",
    "            valid = matches > -1\n",
    "            num_matches = np.sum(valid)\n",
    "            avg_confidence = confidence[valid].mean() if num_matches > 0 else 0\n",
    "            \n",
    "            sinkhorn_results.append({\n",
    "                'iterations': sinkhorn_iters,\n",
    "                'matches': num_matches,\n",
    "                'confidence': avg_confidence,\n",
    "                'time_ms': processing_time * 1000,\n",
    "                'keypoints_0': len(kpts0),\n",
    "                'keypoints_1': len(kpts1)\n",
    "            })\n",
    "        \n",
    "        vs_test.cleanup()\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nSinkhorn Iteration Analysis Results:\")\n",
    "        print(\"Iterations | Matches | Avg Confidence | Time (ms)\")\n",
    "        print(\"-\" * 50)\n",
    "        for result in sinkhorn_results:\n",
    "            print(f\"{result['iterations']:9d} | {result['matches']:7d} | {result['confidence']:12.3f} | {result['time_ms']:8.1f}\")\n",
    "        \n",
    "        # Plot comparison\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        iterations = [r['iterations'] for r in sinkhorn_results]\n",
    "        matches = [r['matches'] for r in sinkhorn_results]\n",
    "        confidences = [r['confidence'] for r in sinkhorn_results]\n",
    "        times = [r['time_ms'] for r in sinkhorn_results]\n",
    "        \n",
    "        # Matches vs iterations\n",
    "        axes[0].plot(iterations, matches, 'bo-', linewidth=2, markersize=8)\n",
    "        axes[0].set_xlabel('Sinkhorn Iterations')\n",
    "        axes[0].set_ylabel('Number of Matches')\n",
    "        axes[0].set_title('Matches vs Sinkhorn Iterations')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Confidence vs iterations\n",
    "        axes[1].plot(iterations, confidences, 'ro-', linewidth=2, markersize=8)\n",
    "        axes[1].set_xlabel('Sinkhorn Iterations')\n",
    "        axes[1].set_ylabel('Average Match Confidence')\n",
    "        axes[1].set_title('Confidence vs Sinkhorn Iterations')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Processing time vs iterations\n",
    "        axes[2].plot(iterations, times, 'go-', linewidth=2, markersize=8)\n",
    "        axes[2].set_xlabel('Sinkhorn Iterations')\n",
    "        axes[2].set_ylabel('Processing Time (ms)')\n",
    "        axes[2].set_title('Processing Time vs Sinkhorn Iterations')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Recommendations\n",
    "        print(\"\\nRecommendations:\")\n",
    "        best_match_idx = np.argmax(matches)\n",
    "        best_confidence_idx = np.argmax(confidences)\n",
    "        fastest_idx = np.argmin(times)\n",
    "        \n",
    "        print(f\"‚Ä¢ Best match count: {iterations[best_match_idx]} iterations ({matches[best_match_idx]} matches)\")\n",
    "        print(f\"‚Ä¢ Best confidence: {iterations[best_confidence_idx]} iterations ({confidences[best_confidence_idx]:.3f} confidence)\")\n",
    "        print(f\"‚Ä¢ Fastest processing: {iterations[fastest_idx]} iterations ({times[fastest_idx]:.1f}ms)\")\n",
    "        \n",
    "        # Find sweet spot (balance of matches and speed)\n",
    "        normalized_matches = np.array(matches) / max(matches)\n",
    "        normalized_times = np.array(times) / max(times)\n",
    "        efficiency_score = normalized_matches - 0.3 * normalized_times  # Weight matches more than speed\n",
    "        best_efficiency_idx = np.argmax(efficiency_score)\n",
    "        \n",
    "        print(f\"‚Ä¢ Recommended (efficiency): {iterations[best_efficiency_idx]} iterations\")\n",
    "        print(f\"  ({matches[best_efficiency_idx]} matches, {confidences[best_efficiency_idx]:.3f} confidence, {times[best_efficiency_idx]:.1f}ms)\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Could not load test frames for Sinkhorn analysis\")\n",
    "else:\n",
    "    print(\"Sinkhorn analysis not available - no video or initialization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "Summary of the SuperGlue demo results and key findings about the Sinkhorn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SuperGlue Demo Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'match_stats' in locals() and len(match_stats['matches_count']) > 0:\n",
    "    print(f\"‚úì Successfully processed {len(match_stats['matches_count'])} frame pairs\")\n",
    "    print(f\"‚úì Average processing speed: {1000/np.mean(match_stats['processing_times']):.1f} FPS\")\n",
    "    print(f\"‚úì Average matches per frame: {np.mean(match_stats['matches_count']):.1f}\")\n",
    "    print(f\"‚úì Using {config['superglue']['sinkhorn_iterations']} Sinkhorn iterations\")\n",
    "    \n",
    "    if SAVE_MATCHES:\n",
    "        print(f\"‚úì Saved matching visualizations to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"‚ö† No processing statistics available\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"‚Ä¢ SuperGlue combines SuperPoint feature detection with learned matching\")\n",
    "print(\"‚Ä¢ The Sinkhorn algorithm enables optimal transport-based feature assignment\")\n",
    "print(\"‚Ä¢ More Sinkhorn iterations generally improve match quality but increase computation time\")\n",
    "print(\"‚Ä¢ Typical sweet spot: 10-20 iterations for real-time applications, 50-100 for accuracy\")\n",
    "\n",
    "if 'sinkhorn_results' in locals():\n",
    "    print(\"\\nSinkhorn Algorithm Insights:\")\n",
    "    print(f\"‚Ä¢ Tested iteration counts: {[r['iterations'] for r in sinkhorn_results]}\")\n",
    "    print(f\"‚Ä¢ Performance varies with scene content and motion\")\n",
    "    print(f\"‚Ä¢ Consider adjusting based on application requirements (speed vs accuracy)\")\n",
    "\n",
    "print(\"\\nOutput Files:\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "if SAVE_MATCHES:\n",
    "    print(\"üìÑ Matching visualizations: match_XXX_YYY.png\")\n",
    "print(\"üìä Performance statistics available in notebook variables\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"‚Ä¢ Experiment with different SuperGlue weights (indoor/outdoor)\")\n",
    "print(\"‚Ä¢ Try different keypoint thresholds and NMS settings\")\n",
    "print(\"‚Ä¢ Test with your own video content\")\n",
    "print(\"‚Ä¢ Integrate with SLAM pipeline for pose estimation\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"SuperGlue Demo Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}