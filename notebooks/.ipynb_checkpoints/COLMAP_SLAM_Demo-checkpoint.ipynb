{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLMAP-SLAM Video Processing Demo\n",
    "\n",
    "This notebook demonstrates how to use the COLMAP-SLAM pipeline to process video files and generate 3D reconstructions.\n",
    "\n",
    "## Overview\n",
    "The pipeline will:\n",
    "1. Extract frames from input video\n",
    "2. Run SLAM reconstruction\n",
    "3. Export 3D point cloud and camera trajectory\n",
    "4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Add COLMAP_SLAM to path\n",
    "sys.path.append('/workspace/COLMAP_SLAM')\n",
    "\n",
    "from pipeline import Pipeline\n",
    "from src import enums\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"Available feature extractors: {[e.name for e in enums.Extractors]}\")\n",
    "print(f\"Available feature matchers: {[e.name for e in enums.Matchers]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the processing parameters and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    # Video processing\n",
    "    'frame_skip': 5,                    # Extract every Nth frame\n",
    "    'max_frames': 100,                  # Maximum frames to process (None for all)\n",
    "    'resize_factor': 1.0,               # Resize frames (1.0 = no resize)\n",
    "    \n",
    "    # SLAM parameters\n",
    "    'init_frames': 30,                  # Frames for initialization\n",
    "    'optical_flow_threshold': 0.05,     # Keyframe selection threshold\n",
    "    'extractor': enums.Extractors.SuperPoint,  # SuperPoint or ORB\n",
    "    'matcher': enums.Matchers.SuperGlue,       # SuperGlue or OrbHamming\n",
    "    \n",
    "    # Paths\n",
    "    'video_dir': '/workspace/videos',\n",
    "    'output_dir': '/workspace/outputs',\n",
    "    'temp_dir': '/workspace/temp'\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [CONFIG['output_dir'], CONFIG['temp_dir']]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path, output_dir, frame_skip=1, max_frames=None, resize_factor=1.0):\n",
    "    \"\"\"\n",
    "    Extract frames from video file.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        output_dir: Directory to save frames\n",
    "        frame_skip: Extract every Nth frame\n",
    "        max_frames: Maximum number of frames to extract\n",
    "        resize_factor: Factor to resize frames\n",
    "    \n",
    "    Returns:\n",
    "        Number of frames extracted\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Video properties:\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    print(f\"  FPS: {fps:.2f}\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    extracted_count = 0\n",
    "    \n",
    "    # Calculate new dimensions if resizing\n",
    "    if resize_factor != 1.0:\n",
    "        new_width = int(width * resize_factor)\n",
    "        new_height = int(height * resize_factor)\n",
    "        print(f\"  Resizing to: {new_width}x{new_height}\")\n",
    "    \n",
    "    pbar = tqdm(total=min(total_frames // frame_skip, max_frames or float('inf')), \n",
    "                desc=\"Extracting frames\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        if frame_count % frame_skip == 0:\n",
    "            # Resize if needed\n",
    "            if resize_factor != 1.0:\n",
    "                frame = cv2.resize(frame, (new_width, new_height))\n",
    "            \n",
    "            # Save frame\n",
    "            frame_filename = f\"frame{extracted_count:06d}.jpg\"\n",
    "            frame_path = os.path.join(output_dir, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            \n",
    "            extracted_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if max_frames and extracted_count >= max_frames:\n",
    "                break\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    pbar.close()\n",
    "    \n",
    "    print(f\"Extracted {extracted_count} frames to {output_dir}\")\n",
    "    return extracted_count\n",
    "\n",
    "\n",
    "def list_video_files(video_dir):\n",
    "    \"\"\"List all video files in directory.\"\"\"\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']\n",
    "    video_files = []\n",
    "    \n",
    "    if os.path.exists(video_dir):\n",
    "        for file in os.listdir(video_dir):\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                video_files.append(os.path.join(video_dir, file))\n",
    "    \n",
    "    return sorted(video_files)\n",
    "\n",
    "\n",
    "def create_output_structure(base_output_dir, video_name):\n",
    "    \"\"\"Create organized output directory structure.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"{video_name}_{timestamp}\"\n",
    "    \n",
    "    output_structure = {\n",
    "        'base': os.path.join(base_output_dir, run_name),\n",
    "        'frames': os.path.join(base_output_dir, run_name, 'frames'),\n",
    "        'reconstruction': os.path.join(base_output_dir, run_name, 'reconstruction'),\n",
    "        'visualization': os.path.join(base_output_dir, run_name, 'visualization')\n",
    "    }\n",
    "    \n",
    "    for path in output_structure.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    return output_structure\n",
    "\n",
    "print(\"✓ Video processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLAM Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slam_pipeline(frames_dir, output_dir, config):\n",
    "    \"\"\"\n",
    "    Run the COLMAP-SLAM pipeline on extracted frames.\n",
    "    \n",
    "    Args:\n",
    "        frames_dir: Directory containing input frames\n",
    "        output_dir: Directory for reconstruction output\n",
    "        config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline object with reconstruction results\n",
    "    \"\"\"\n",
    "    print(\"Initializing SLAM pipeline...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(\n",
    "        extractor=config['extractor'],\n",
    "        matcher=config['matcher']\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"Loading frames from: {frames_dir}\")\n",
    "    pipeline.load_data(\n",
    "        images=frames_dir,\n",
    "        outputs=output_dir,\n",
    "        exports=\"reconstruction.ply\",\n",
    "        init_max_num_images=config['init_frames'],\n",
    "        frame_skip=1,  # Already skipped during extraction\n",
    "        max_frame=-1   # Process all extracted frames\n",
    "    )\n",
    "    \n",
    "    print(f\"Loaded {len(pipeline.frame_names)} frames for processing\")\n",
    "    \n",
    "    # Run SLAM\n",
    "    print(\"Running SLAM reconstruction...\")\n",
    "    print(f\"Using {config['extractor'].name} features and {config['matcher'].name} matching\")\n",
    "    \n",
    "    pipeline.run(optical_flow_threshold=config['optical_flow_threshold'])\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nReconstruction complete!\")\n",
    "    print(pipeline.reconstruction.summary())\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def export_results(pipeline, output_dir):\n",
    "    \"\"\"\n",
    "    Export reconstruction results in various formats.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: SLAM pipeline object\n",
    "        output_dir: Directory to save exports\n",
    "    \"\"\"\n",
    "    print(\"Exporting reconstruction results...\")\n",
    "    \n",
    "    # Export COLMAP binary files\n",
    "    colmap_dir = os.path.join(output_dir, 'colmap')\n",
    "    os.makedirs(colmap_dir, exist_ok=True)\n",
    "    pipeline.reconstruction.write(colmap_dir)\n",
    "    print(f\"✓ COLMAP files saved to: {colmap_dir}\")\n",
    "    \n",
    "    # Export trajectory (already done by pipeline)\n",
    "    traj_file = os.path.join(output_dir, 'estimation.txt')\n",
    "    if os.path.exists(traj_file):\n",
    "        print(f\"✓ Camera trajectory saved to: {traj_file}\")\n",
    "    \n",
    "    # Export PLY point cloud\n",
    "    try:\n",
    "        ply_file = os.path.join(output_dir, 'pointcloud.ply')\n",
    "        pipeline.reconstruction.export_PLY(ply_file)\n",
    "        print(f\"✓ Point cloud saved to: {ply_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not export PLY: {e}\")\n",
    "    \n",
    "    # Generate summary report\n",
    "    summary_file = os.path.join(output_dir, 'reconstruction_summary.txt')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"COLMAP-SLAM Reconstruction Summary\\n\")\n",
    "        f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "        f.write(pipeline.reconstruction.summary())\n",
    "        f.write(\"\\n\\nConfiguration:\\n\")\n",
    "        for key, value in CONFIG.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(f\"✓ Summary report saved to: {summary_file}\")\n",
    "\n",
    "print(\"✓ SLAM processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_camera_trajectory(pipeline, output_dir):\n",
    "    \"\"\"\n",
    "    Plot and save camera trajectory visualization.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: SLAM pipeline object\n",
    "        output_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    if len(pipeline.reconstruction.images) == 0:\n",
    "        print(\"No registered images to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract camera positions\n",
    "    positions = []\n",
    "    image_ids = []\n",
    "    \n",
    "    for img_id in sorted(pipeline.reconstruction.images.keys()):\n",
    "        image = pipeline.reconstruction.images[img_id]\n",
    "        # Camera center in world coordinates\n",
    "        center = -image.rotmat().T @ image.tvec\n",
    "        positions.append(center)\n",
    "        image_ids.append(img_id)\n",
    "    \n",
    "    positions = np.array(positions)\n",
    "    \n",
    "    # Create 3D trajectory plot\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 3D plot\n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    ax1.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'b-', alpha=0.7)\n",
    "    ax1.scatter(positions[:, 0], positions[:, 1], positions[:, 2], c=range(len(positions)), cmap='viridis', s=20)\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_title('3D Camera Trajectory')\n",
    "    \n",
    "    # Top view (X-Y)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.plot(positions[:, 0], positions[:, 1], 'b-', alpha=0.7)\n",
    "    ax2.scatter(positions[:, 0], positions[:, 1], c=range(len(positions)), cmap='viridis', s=20)\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Y')\n",
    "    ax2.set_title('Top View (X-Y)')\n",
    "    ax2.axis('equal')\n",
    "    \n",
    "    # Side view (X-Z)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax3.plot(positions[:, 0], positions[:, 2], 'b-', alpha=0.7)\n",
    "    ax3.scatter(positions[:, 0], positions[:, 2], c=range(len(positions)), cmap='viridis', s=20)\n",
    "    ax3.set_xlabel('X')\n",
    "    ax3.set_ylabel('Z')\n",
    "    ax3.set_title('Side View (X-Z)')\n",
    "    ax3.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_file = os.path.join(output_dir, 'camera_trajectory.png')\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Camera trajectory plot saved to: {plot_file}\")\n",
    "    \n",
    "    # Print trajectory statistics\n",
    "    total_distance = np.sum(np.linalg.norm(np.diff(positions, axis=0), axis=1))\n",
    "    bbox_size = np.max(positions, axis=0) - np.min(positions, axis=0)\n",
    "    \n",
    "    print(f\"Trajectory statistics:\")\n",
    "    print(f\"  Total path length: {total_distance:.3f} units\")\n",
    "    print(f\"  Bounding box size: {bbox_size}\")\n",
    "    print(f\"  Number of poses: {len(positions)}\")\n",
    "\n",
    "\n",
    "def plot_reconstruction_stats(pipeline, output_dir):\n",
    "    \"\"\"\n",
    "    Plot reconstruction statistics.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: SLAM pipeline object\n",
    "        output_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Number of observations per point\n",
    "    if len(pipeline.reconstruction.points3D) > 0:\n",
    "        obs_counts = [len(point.track.elements) for point in pipeline.reconstruction.points3D.values()]\n",
    "        axes[0,0].hist(obs_counts, bins=20, alpha=0.7)\n",
    "        axes[0,0].set_xlabel('Number of Observations')\n",
    "        axes[0,0].set_ylabel('Number of Points')\n",
    "        axes[0,0].set_title('Point Observation Distribution')\n",
    "    \n",
    "    # Track lengths\n",
    "    if len(pipeline.reconstruction.points3D) > 0:\n",
    "        track_lengths = obs_counts  # Same as observations\n",
    "        axes[0,1].hist(track_lengths, bins=20, alpha=0.7, color='orange')\n",
    "        axes[0,1].set_xlabel('Track Length')\n",
    "        axes[0,1].set_ylabel('Number of Tracks')\n",
    "        axes[0,1].set_title('Track Length Distribution')\n",
    "    \n",
    "    # Image registration order\n",
    "    if len(pipeline.reconstruction.images) > 0:\n",
    "        image_ids = sorted(pipeline.reconstruction.images.keys())\n",
    "        axes[1,0].plot(range(len(image_ids)), image_ids, 'o-')\n",
    "        axes[1,0].set_xlabel('Registration Order')\n",
    "        axes[1,0].set_ylabel('Image ID')\n",
    "        axes[1,0].set_title('Image Registration Order')\n",
    "    \n",
    "    # Point cloud extent\n",
    "    if len(pipeline.reconstruction.points3D) > 0:\n",
    "        points = np.array([point.xyz for point in pipeline.reconstruction.points3D.values()])\n",
    "        axes[1,1].scatter(points[:, 0], points[:, 1], alpha=0.5, s=1)\n",
    "        axes[1,1].set_xlabel('X')\n",
    "        axes[1,1].set_ylabel('Y')\n",
    "        axes[1,1].set_title('Point Cloud (Top View)')\n",
    "        axes[1,1].axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_file = os.path.join(output_dir, 'reconstruction_stats.png')\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Reconstruction statistics plot saved to: {plot_file}\")\n",
    "\n",
    "print(\"✓ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Pipeline\n",
    "\n",
    "Select and process a video file through the complete SLAM pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available video files\n",
    "video_files = list_video_files(CONFIG['video_dir'])\n",
    "\n",
    "print(f\"Found {len(video_files)} video files in {CONFIG['video_dir']}:\")\n",
    "for i, video_file in enumerate(video_files):\n",
    "    file_size = os.path.getsize(video_file) / (1024*1024)  # MB\n",
    "    print(f\"  {i}: {os.path.basename(video_file)} ({file_size:.1f} MB)\")\n",
    "\n",
    "if len(video_files) == 0:\n",
    "    print(\"\\n⚠ No video files found!\")\n",
    "    print(f\"Please place video files in: {CONFIG['video_dir']}\")\n",
    "    print(\"Supported formats: .mp4, .avi, .mov, .mkv, .wmv, .flv, .webm\")\n",
    "else:\n",
    "    print(f\"\\n📁 To process a video, run the next cell and select a video by index (0-{len(video_files)-1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select video to process\n",
    "if len(video_files) > 0:\n",
    "    # Change this index to select different video\n",
    "    video_index = 0  # <-- CHANGE THIS to select different video\n",
    "    \n",
    "    if video_index >= len(video_files):\n",
    "        print(f\"❌ Invalid video index {video_index}. Available indices: 0-{len(video_files)-1}\")\n",
    "    else:\n",
    "        selected_video = video_files[video_index]\n",
    "        video_name = os.path.splitext(os.path.basename(selected_video))[0]\n",
    "        \n",
    "        print(f\"Selected video: {os.path.basename(selected_video)}\")\n",
    "        print(f\"Video name: {video_name}\")\n",
    "        \n",
    "        # Create output structure\n",
    "        outputs = create_output_structure(CONFIG['output_dir'], video_name)\n",
    "        \n",
    "        print(f\"\\nOutput directories:\")\n",
    "        for key, path in outputs.items():\n",
    "            print(f\"  {key}: {path}\")\nelse:\n",
    "    print(\"❌ No video files available to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'selected_video' in locals():\n",
    "    print(f\"🎬 Extracting frames from: {os.path.basename(selected_video)}\")\n",
    "    \n",
    "    # Extract frames\n",
    "    num_frames = extract_frames_from_video(\n",
    "        video_path=selected_video,\n",
    "        output_dir=outputs['frames'],\n",
    "        frame_skip=CONFIG['frame_skip'],\n",
    "        max_frames=CONFIG['max_frames'],\n",
    "        resize_factor=CONFIG['resize_factor']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Frame extraction complete!\")\n",
    "    print(f\"Extracted {num_frames} frames to: {outputs['frames']}\")\n",
    "    \n",
    "    # Show sample frames\n",
    "    frame_files = sorted(os.listdir(outputs['frames']))[:4]  # Show first 4 frames\n",
    "    \n",
    "    if frame_files:\n",
    "        fig, axes = plt.subplots(1, min(4, len(frame_files)), figsize=(15, 4))\n",
    "        if len(frame_files) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, frame_file in enumerate(frame_files):\n",
    "            if i >= 4:\n",
    "                break\n",
    "            frame_path = os.path.join(outputs['frames'], frame_file)\n",
    "            img = cv2.imread(frame_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if len(frame_files) > 1:\n",
    "                axes[i].imshow(img_rgb)\n",
    "                axes[i].set_title(f\"Frame {i+1}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes.imshow(img_rgb)\n",
    "                axes.set_title(f\"Frame 1\")\n",
    "                axes.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\nelse:\n",
    "    print(\"❌ No video selected. Please run the video selection cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run SLAM Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'outputs' in locals() and 'num_frames' in locals():\n",
    "    print(f\"🚀 Starting SLAM reconstruction...\")\n",
    "    print(f\"Processing {num_frames} frames from: {outputs['frames']}\")\n",
    "    \n",
    "    try:\n",
    "        # Run SLAM pipeline\n",
    "        pipeline = run_slam_pipeline(\n",
    "            frames_dir=outputs['frames'],\n",
    "            output_dir=outputs['reconstruction'],\n",
    "            config=CONFIG\n",
    "        )\n",
    "        \n",
    "        print(\"\\n🎉 SLAM reconstruction completed successfully!\")\n",
    "        print(f\"Results saved to: {outputs['reconstruction']}\")\n",
    "        \n",
    "        # Export results\n",
    "        export_results(pipeline, outputs['reconstruction'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ SLAM reconstruction failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\nelse:\n",
    "    print(\"❌ Frames not extracted yet. Please run the frame extraction step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pipeline' in locals():\n",
    "    print(\"📊 Generating visualizations...\")\n",
    "    \n",
    "    # Plot camera trajectory\n",
    "    plot_camera_trajectory(pipeline, outputs['visualization'])\n",
    "    \n",
    "    # Plot reconstruction statistics\n",
    "    plot_reconstruction_stats(pipeline, outputs['visualization'])\n",
    "    \n",
    "    print(\"\\n✅ Visualization complete!\")\n",
    "    print(f\"Plots saved to: {outputs['visualization']}\")\nelse:\n",
    "    print(\"❌ No reconstruction results available. Please run the SLAM step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pipeline' in locals() and 'outputs' in locals():\n",
    "    print(\"📋 RECONSTRUCTION SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Input video: {os.path.basename(selected_video)}\")\n",
    "    print(f\"Processed frames: {num_frames}\")\n",
    "    print(f\"Output directory: {outputs['base']}\")\n",
    "    \n",
    "    print(\"\\nReconstruction statistics:\")\n",
    "    print(pipeline.reconstruction.summary())\n",
    "    \n",
    "    print(\"\\nGenerated files:\")\n",
    "    \n",
    "    # List key output files\n",
    "    key_files = [\n",
    "        (outputs['reconstruction'], 'colmap/cameras.bin', 'COLMAP camera parameters'),\n",
    "        (outputs['reconstruction'], 'colmap/images.bin', 'COLMAP image poses'),\n",
    "        (outputs['reconstruction'], 'colmap/points3D.bin', 'COLMAP 3D points'),\n",
    "        (outputs['reconstruction'], 'estimation.txt', 'Camera trajectory (TUM format)'),\n",
    "        (outputs['reconstruction'], 'reconstruction_summary.txt', 'Detailed summary'),\n",
    "        (outputs['visualization'], 'camera_trajectory.png', 'Trajectory visualization'),\n",
    "        (outputs['visualization'], 'reconstruction_stats.png', 'Statistics plots')\n",
    "    ]\n",
    "    \n",
    "    for base_dir, rel_path, description in key_files:\n",
    "        full_path = os.path.join(base_dir, rel_path)\n",
    "        if os.path.exists(full_path):\n",
    "            size = os.path.getsize(full_path)\n",
    "            if size > 1024*1024:\n",
    "                size_str = f\"{size/(1024*1024):.1f} MB\"\n",
    "            elif size > 1024:\n",
    "                size_str = f\"{size/1024:.1f} KB\"\n",
    "            else:\n",
    "                size_str = f\"{size} B\"\n",
    "            print(f\"  ✓ {rel_path} ({size_str}) - {description}\")\n",
    "        else:\n",
    "            print(f\"  ✗ {rel_path} - {description} (not found)\")\n",
    "    \n",
    "    print(f\"\\n🎯 All results saved to: {outputs['base']}\")\n",
    "    print(f\"📁 This directory is mounted to the host at: ./outputs/{os.path.basename(outputs['base'])}\")\nelse:\n",
    "    print(\"❌ No results to summarize. Please complete the reconstruction pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Batch Processing Multiple Videos\n",
    "\n",
    "Uncomment and run the cell below to process all videos in the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch process all videos (uncomment to use)\n",
    "# if len(video_files) > 1:\n",
    "#     print(f\"🔄 Batch processing {len(video_files)} videos...\")\n",
    "#     \n",
    "#     for i, video_path in enumerate(video_files):\n",
    "#         print(f\"\\n{'='*50}\")\n",
    "#         print(f\"Processing video {i+1}/{len(video_files)}: {os.path.basename(video_path)}\")\n",
    "#         print(f\"{'='*50}\")\n",
    "#         \n",
    "#         try:\n",
    "#             video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "#             batch_outputs = create_output_structure(CONFIG['output_dir'], video_name)\n",
    "#             \n",
    "#             # Extract frames\n",
    "#             num_frames = extract_frames_from_video(\n",
    "#                 video_path=video_path,\n",
    "#                 output_dir=batch_outputs['frames'],\n",
    "#                 frame_skip=CONFIG['frame_skip'],\n",
    "#                 max_frames=CONFIG['max_frames'],\n",
    "#                 resize_factor=CONFIG['resize_factor']\n",
    "#             )\n",
    "#             \n",
    "#             # Run SLAM\n",
    "#             batch_pipeline = run_slam_pipeline(\n",
    "#                 frames_dir=batch_outputs['frames'],\n",
    "#                 output_dir=batch_outputs['reconstruction'],\n",
    "#                 config=CONFIG\n",
    "#             )\n",
    "#             \n",
    "#             # Export and visualize\n",
    "#             export_results(batch_pipeline, batch_outputs['reconstruction'])\n",
    "#             plot_camera_trajectory(batch_pipeline, batch_outputs['visualization'])\n",
    "#             plot_reconstruction_stats(batch_pipeline, batch_outputs['visualization'])\n",
    "#             \n",
    "#             print(f\"✅ Video {i+1} completed successfully\")\n",
    "#             \n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Video {i+1} failed: {e}\")\n",
    "#             continue\n",
    "#     \n",
    "#     print(f\"\\n🎉 Batch processing completed!\")\n",
    "# else:\n",
    "#     print(\"Only one video available - use single video processing instead\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}