{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArUco Camera Calibration and Pose Estimation\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. ArUco board detection using OpenCV\n",
    "2. Camera calibration using detected ArUco boards\n",
    "3. Distance and pose estimation of ArUco boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../outputs/aruco_calibration\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup ArUco Dictionary and Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArUco setup\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Create ArUco board (5x7 grid, marker size 0.04m, separation 0.01m)\n",
    "board = cv2.aruco.GridBoard((5, 7), 0.04, 0.01, dictionary)\n",
    "\n",
    "# Generate and save board image\n",
    "board_img = board.generateImage((1000, 1400))\n",
    "cv2.imwrite(str(output_dir / \"aruco_board.png\"), board_img)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(board_img, cmap='gray')\n",
    "plt.title(\"ArUco Calibration Board (5x7)\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"board_preview.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Board saved to: {output_dir / 'aruco_board.png'}\")\n",
    "print(\"Print this board on paper for calibration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capture Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_calibration_images(num_images=10):\n",
    "    \"\"\"Capture images for calibration using webcam.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return []\n",
    "    \n",
    "    images = []\n",
    "    img_count = 0\n",
    "    \n",
    "    print(f\"Capturing {num_images} calibration images...\")\n",
    "    print(\"Press SPACE to capture, ESC to exit, 'q' to quit early\")\n",
    "    \n",
    "    while img_count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect ArUco markers\n",
    "        corners, ids, _ = detector.detectMarkers(frame)\n",
    "        \n",
    "        # Draw detected markers\n",
    "        display_frame = frame.copy()\n",
    "        if ids is not None:\n",
    "            cv2.aruco.drawDetectedMarkers(display_frame, corners, ids)\n",
    "            cv2.putText(display_frame, f\"Markers: {len(ids)}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(display_frame, f\"Images: {img_count}/{num_images}\", (10, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.putText(display_frame, \"SPACE: capture, ESC/q: quit\", (10, frame.shape[0]-20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Calibration Capture', display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 32:  # Space key\n",
    "            if ids is not None and len(ids) >= 10:  # Need enough markers\n",
    "                images.append(frame.copy())\n",
    "                img_count += 1\n",
    "                print(f\"Captured image {img_count} with {len(ids)} markers\")\n",
    "            else:\n",
    "                print(\"Not enough markers detected. Move closer to board.\")\n",
    "        elif key == 27 or key == ord('q'):  # ESC or 'q'\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return images\n",
    "\n",
    "# Uncomment to capture live images\n",
    "# calibration_images = capture_calibration_images(15)\n",
    "\n",
    "# For demo purposes, use sample images from a directory if available\n",
    "calib_dir = Path(\"../data/calibration_images\")\n",
    "if calib_dir.exists():\n",
    "    calibration_images = [cv2.imread(str(img)) for img in calib_dir.glob(\"*.jpg\")]\n",
    "    print(f\"Loaded {len(calibration_images)} images from {calib_dir}\")\n",
    "else:\n",
    "    print(\"No calibration images directory found.\")\n",
    "    print(\"Uncomment the capture_calibration_images() call above to capture live images.\")\n",
    "    calibration_images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(images, board):\n",
    "    \"\"\"Calibrate camera using ArUco board images.\"\"\"\n",
    "    all_corners = []\n",
    "    all_ids = []\n",
    "    \n",
    "    # Detect markers in all images\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = detector.detectMarkers(gray)\n",
    "        \n",
    "        if ids is not None and len(ids) >= 4:\n",
    "            all_corners.append(corners)\n",
    "            all_ids.append(ids)\n",
    "    \n",
    "    if len(all_corners) == 0:\n",
    "        print(\"No valid images with enough markers found\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Get image size\n",
    "    img_size = (images[0].shape[1], images[0].shape[0])\n",
    "    \n",
    "    # Calibrate camera\n",
    "    ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.aruco.calibrateCameraAruco(\n",
    "        all_corners, all_ids, board, img_size, None, None\n",
    "    )\n",
    "    \n",
    "    return ret, camera_matrix, dist_coeffs, rvecs, tvecs\n",
    "\n",
    "if calibration_images:\n",
    "    print(f\"Calibrating camera with {len(calibration_images)} images...\")\n",
    "    \n",
    "    ret, camera_matrix, dist_coeffs, rvecs, tvecs = calibrate_camera(calibration_images, board)\n",
    "    \n",
    "    if ret is not None:\n",
    "        print(f\"Calibration successful! RMS error: {ret:.3f}\")\n",
    "        print(f\"Camera matrix:\\n{camera_matrix}\")\n",
    "        print(f\"Distortion coefficients: {dist_coeffs.flatten()}\")\n",
    "        \n",
    "        # Save calibration data\n",
    "        calib_data = {\n",
    "            'camera_matrix': camera_matrix.tolist(),\n",
    "            'dist_coeffs': dist_coeffs.tolist(),\n",
    "            'rms_error': float(ret)\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / 'camera_calibration.json', 'w') as f:\n",
    "            json.dump(calib_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Calibration saved to: {output_dir / 'camera_calibration.json'}\")\n",
    "    else:\n",
    "        print(\"Calibration failed\")\n",
    "        camera_matrix = None\n",
    "        dist_coeffs = None\n",
    "else:\n",
    "    print(\"No calibration images available. Using default camera parameters.\")\n",
    "    # Default camera matrix for demo (adjust for your camera)\n",
    "    camera_matrix = np.array([[800, 0, 320],\n",
    "                             [0, 800, 240],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "    dist_coeffs = np.zeros((4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Live Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose_live(camera_matrix, dist_coeffs, board):\n",
    "    \"\"\"Live pose estimation of ArUco board.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return\n",
    "    \n",
    "    print(\"Live pose estimation started. Press ESC or 'q' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = detector.detectMarkers(gray)\n",
    "        \n",
    "        if ids is not None and len(ids) >= 4:\n",
    "            # Draw detected markers\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "            \n",
    "            # Estimate pose\n",
    "            obj_points, img_points = board.matchImagePoints(corners, ids)\n",
    "            \n",
    "            if len(obj_points) >= 4:\n",
    "                success, rvec, tvec = cv2.solvePnP(\n",
    "                    obj_points, img_points, camera_matrix, dist_coeffs\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    # Draw coordinate axes\n",
    "                    cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.1)\n",
    "                    \n",
    "                    # Calculate distance and angles\n",
    "                    distance = np.linalg.norm(tvec)\n",
    "                    \n",
    "                    # Convert rotation vector to rotation matrix\n",
    "                    rmat, _ = cv2.Rodrigues(rvec)\n",
    "                    \n",
    "                    # Extract Euler angles (roll, pitch, yaw)\n",
    "                    sy = np.sqrt(rmat[0,0]**2 + rmat[1,0]**2)\n",
    "                    singular = sy < 1e-6\n",
    "                    \n",
    "                    if not singular:\n",
    "                        roll = np.arctan2(rmat[2,1], rmat[2,2]) * 180/np.pi\n",
    "                        pitch = np.arctan2(-rmat[2,0], sy) * 180/np.pi\n",
    "                        yaw = np.arctan2(rmat[1,0], rmat[0,0]) * 180/np.pi\n",
    "                    else:\n",
    "                        roll = np.arctan2(-rmat[1,2], rmat[1,1]) * 180/np.pi\n",
    "                        pitch = np.arctan2(-rmat[2,0], sy) * 180/np.pi\n",
    "                        yaw = 0\n",
    "                    \n",
    "                    # Display information\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}m\", (10, 30), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Roll: {roll:.1f}°\", (10, 60), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Pitch: {pitch:.1f}°\", (10, 90), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Yaw: {yaw:.1f}°\", (10, 120), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Markers: {len(ids)}\", (10, 150), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"ESC or 'q' to quit\", (10, frame.shape[0]-20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('ArUco Pose Estimation', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27 or key == ord('q'):  # ESC or 'q'\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if camera_matrix is not None:\n",
    "    print(\"Ready for live pose estimation!\")\n",
    "    print(\"Uncomment the line below to start live pose estimation:\")\n",
    "    # estimate_pose_live(camera_matrix, dist_coeffs, board)\n",
    "else:\n",
    "    print(\"Camera calibration required for accurate pose estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test with Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pose_estimation(image_path, camera_matrix, dist_coeffs, board):\n",
    "    \"\"\"Test pose estimation on a single image.\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "    \n",
    "    if ids is not None:\n",
    "        # Draw detected markers\n",
    "        cv2.aruco.drawDetectedMarkers(img, corners, ids)\n",
    "        \n",
    "        # Estimate pose\n",
    "        obj_points, img_points = board.matchImagePoints(corners, ids)\n",
    "        \n",
    "        if len(obj_points) >= 4:\n",
    "            success, rvec, tvec = cv2.solvePnP(\n",
    "                obj_points, img_points, camera_matrix, dist_coeffs\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                # Draw coordinate axes\n",
    "                cv2.drawFrameAxes(img, camera_matrix, dist_coeffs, rvec, tvec, 0.1)\n",
    "                \n",
    "                distance = np.linalg.norm(tvec)\n",
    "                print(f\"Distance to board: {distance:.2f}m\")\n",
    "                print(f\"Translation vector: {tvec.flatten()}\")\n",
    "                print(f\"Rotation vector: {rvec.flatten()}\")\n",
    "    \n",
    "    # Display result\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"ArUco Pose Estimation - {image_path.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test with calibration images if available\n",
    "if calibration_images and camera_matrix is not None:\n",
    "    print(\"Testing pose estimation on first calibration image:\")\n",
    "    # Save first image for testing\n",
    "    test_img_path = output_dir / \"test_image.jpg\"\n",
    "    cv2.imwrite(str(test_img_path), calibration_images[0])\n",
    "    test_pose_estimation(test_img_path, camera_matrix, dist_coeffs, board)\n",
    "else:\n",
    "    print(\"No test images available or camera not calibrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **ArUco Board Generation**: Creates a 5x7 ArUco calibration board\n",
    "2. **Camera Calibration**: Uses multiple images of the board to calibrate camera intrinsics\n",
    "3. **Live Pose Estimation**: Real-time detection and pose estimation of the ArUco board\n",
    "4. **Distance and Orientation**: Calculates 3D distance and Euler angles (roll, pitch, yaw)\n",
    "\n",
    "**Usage Instructions**:\n",
    "1. Print the generated ArUco board (`aruco_board.png`)\n",
    "2. Uncomment `capture_calibration_images()` to capture calibration images\n",
    "3. Uncomment `estimate_pose_live()` for real-time pose estimation\n",
    "\n",
    "**Outputs**:\n",
    "- `aruco_board.png`: Printable calibration board\n",
    "- `camera_calibration.json`: Camera intrinsic parameters\n",
    "- Real-time distance and orientation measurements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}