{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLoC Camera Pose Estimation Pipeline\n",
    "\n",
    "This notebook demonstrates camera pose estimation from images/videos using HLoC (Hierarchical Localization) in a dockerized environment.\n",
    "\n",
    "## Features:\n",
    "- Process images or videos as input\n",
    "- Extract features using state-of-the-art extractors (SuperPoint, ALIKED, etc.)\n",
    "- Match features using various matchers (SuperGlue, LightGlue, etc.)\n",
    "- Perform Structure-from-Motion (SfM) reconstruction\n",
    "- Export camera poses for all frames\n",
    "- Visualize 3D reconstruction and camera poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "\n",
    "# If error: prepend the following to hloc/hloc/reconstruction.py\n",
    "# from __future__ import annotations\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Add hloc module to path\n",
    "import sys\n",
    "sys.path.append('../modules/hloc')\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive,\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "import pycolmap # ignore version warnings from hloc, anything >= 0.6.1 will do fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure input/output paths and processing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_DIR = Path(\"../videos\")  # Can contain videos or image sequences\n",
    "OUTPUT_DIR = Path(\"../outputs/hloc_poses\")\n",
    "TEMP_DIR = Path(\"../temp/hloc_processing\")\n",
    "\n",
    "# Feature extraction and matching configurations\n",
    "# Available extractors: superpoint_aachen, aliked, disk, d2net, r2d2\n",
    "FEATURE_EXTRACTOR = \"superpoint_aachen\"  # or \"aliked-n16\"\n",
    "FEATURE_MATCHER = \"superglue\"     # or \"lightglue\", \"nearest_neighbor\"\n",
    "\n",
    "# Processing parameters\n",
    "MAX_IMAGES = 100  # Limit number of frames for processing\n",
    "# Get frame sampling rate from environment variable, default to 1 (keep all)\n",
    "FRAME_SKIP = int(os.getenv('FRAME_SAMPLE_RATE', 2))  # Extract every N-th frame from videos\n",
    "RESIZE_MAX = 1024 # Maximum image dimension\n",
    "\n",
    "# Create directories\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Input directory: {INPUT_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Temporary directory: {TEMP_DIR}\")\n",
    "print(f\"Feature extractor: {FEATURE_EXTRACTOR}\")\n",
    "print(f\"Feature matcher: {FEATURE_MATCHER}\")\n",
    "print(f\"Frame sampling rate: {FRAME_SKIP} (every {FRAME_SKIP}th frame)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Processing\n",
    "\n",
    "Process input videos and images, extracting frames as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path, output_dir, frame_skip=1, max_frames=100):\n",
    "    \"\"\"Extract frames from video file.\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = 0\n",
    "    extracted_count = 0\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    while cap.isOpened() and extracted_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        if frame_count % frame_skip == 0:\n",
    "            frame_filename = output_dir / f\"frame_{extracted_count:06d}.jpg\"\n",
    "            cv2.imwrite(str(frame_filename), frame)\n",
    "            extracted_count += 1\n",
    "            \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted {extracted_count} frames from {video_path.name}\")\n",
    "    return extracted_count\n",
    "\n",
    "def process_input_files():\n",
    "    \"\"\"Process all input files (videos and images).\"\"\"\n",
    "    images_dir = TEMP_DIR / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "    \n",
    "    processed_files = []\n",
    "    total_images = 0\n",
    "    \n",
    "    if not INPUT_DIR.exists():\n",
    "        print(f\"Warning: Input directory {INPUT_DIR} does not exist!\")\n",
    "        return [], 0\n",
    "    \n",
    "    for file_path in INPUT_DIR.iterdir():\n",
    "        if file_path.is_file():\n",
    "            file_ext = file_path.suffix.lower()\n",
    "            \n",
    "            if file_ext in video_extensions:\n",
    "                print(f\"Processing video: {file_path.name}\")\n",
    "                video_output_dir = images_dir / file_path.stem\n",
    "                frame_count = extract_frames_from_video(\n",
    "                    file_path, video_output_dir, FRAME_SKIP, MAX_IMAGES\n",
    "                )\n",
    "                total_images += frame_count\n",
    "                processed_files.append((file_path, 'video', frame_count))\n",
    "                \n",
    "            elif file_ext in image_extensions:\n",
    "                print(f\"Copying image: {file_path.name}\")\n",
    "                dest_path = images_dir / file_path.name\n",
    "                shutil.copy2(file_path, dest_path)\n",
    "                total_images += 1\n",
    "                processed_files.append((file_path, 'image', 1))\n",
    "    \n",
    "    print(f\"\\nTotal images to process: {total_images}\")\n",
    "    return processed_files, total_images\n",
    "\n",
    "# Process input files\n",
    "processed_files, total_image_count = process_input_files()\n",
    "\n",
    "if total_image_count == 0:\n",
    "    print(\"No valid input files found! Please add videos or images to the input directory.\")\n",
    "else:\n",
    "    print(f\"\\nProcessed files summary:\")\n",
    "    for file_path, file_type, count in processed_files:\n",
    "        print(f\"  {file_path.name} ({file_type}): {count} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect and Display Images\n",
    "\n",
    "Collect all processed images and display a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_list():\n",
    "    \"\"\"Collect all images from the processing directory.\"\"\"\n",
    "    images_dir = TEMP_DIR / \"images\"\n",
    "    image_list = []\n",
    "    \n",
    "    if not images_dir.exists():\n",
    "        return image_list\n",
    "    \n",
    "    # Collect all images from subdirectories and root\n",
    "    for file_path in images_dir.rglob(\"*\"):\n",
    "        if file_path.is_file() and file_path.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}:\n",
    "            # Convert to relative path from images_dir\n",
    "            rel_path = file_path.relative_to(images_dir)\n",
    "            image_list.append(rel_path.as_posix())\n",
    "    \n",
    "    image_list.sort()\n",
    "    return image_list\n",
    "\n",
    "# Collect images\n",
    "images_base = TEMP_DIR / \"images\"\n",
    "image_list = collect_image_list()\n",
    "\n",
    "print(f\"Found {len(image_list)} images for processing\")\n",
    "\n",
    "if len(image_list) > 0:\n",
    "    # Display a sample of images\n",
    "    sample_size = min(6, len(image_list))\n",
    "    sample_indices = np.linspace(0, len(image_list)-1, sample_size, dtype=int)\n",
    "    sample_images = [read_image(images_base / image_list[i]) for i in sample_indices]\n",
    "    \n",
    "    print(f\"\\nDisplaying sample of {sample_size} images:\")\n",
    "    plot_images(sample_images, dpi=50)\n",
    "    \n",
    "    print(f\"\\nFirst few image names:\")\n",
    "    for i, img_name in enumerate(image_list[:10]):\n",
    "        print(f\"  {i+1}: {img_name}\")\n",
    "else:\n",
    "    print(\"No images found for processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Matching\n",
    "\n",
    "Extract features from all images and match them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(image_list) == 0:\n",
    "    print(\"Skipping feature extraction - no images available\")\n",
    "else:\n",
    "    # Set up output paths\n",
    "    sfm_pairs = OUTPUT_DIR / \"pairs-sfm.txt\"\n",
    "    features = OUTPUT_DIR / \"features.h5\"\n",
    "    matches = OUTPUT_DIR / \"matches.h5\"\n",
    "    \n",
    "    # Configure feature extractor and matcher\n",
    "    feature_conf = extract_features.confs[FEATURE_EXTRACTOR]\n",
    "    if FEATURE_MATCHER == \"superglue\":\n",
    "        matcher_conf = match_features.confs[\"superglue\"]\n",
    "    elif FEATURE_EXTRACTOR.startswith(\"aliked\") and FEATURE_MATCHER == \"lightglue\":\n",
    "        matcher_conf = match_features.confs[\"aliked+lightglue\"]\n",
    "    else:\n",
    "        matcher_conf = match_features.confs[\"nearest_neighbor\"]\n",
    "    \n",
    "    print(f\"Feature extraction configuration: {feature_conf}\")\n",
    "    print(f\"Matching configuration: {matcher_conf}\")\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"\\nExtracting features...\")\n",
    "    extract_features.main(\n",
    "        feature_conf, images_base, image_list=image_list, feature_path=features\n",
    "    )\n",
    "    \n",
    "    # Generate image pairs (exhaustive for smaller datasets)\n",
    "    print(\"\\nGenerating image pairs...\")\n",
    "    pairs_from_exhaustive.main(sfm_pairs, image_list=image_list)\n",
    "    \n",
    "    # Match features\n",
    "    print(\"\\nMatching features...\")\n",
    "    match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches)\n",
    "    \n",
    "    print(\"\\nFeature extraction and matching completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure-from-Motion Reconstruction\n",
    "\n",
    "Perform 3D reconstruction to estimate camera poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(image_list) == 0:\n",
    "    print(\"Skipping SfM reconstruction - no images available\")\n",
    "else:\n",
    "    # Set up SfM output directory\n",
    "    sfm_dir = OUTPUT_DIR / \"sfm\"\n",
    "    \n",
    "    print(\"Running Structure-from-Motion reconstruction...\")\n",
    "    \n",
    "    # Run SfM reconstruction\n",
    "    model = reconstruction.main(\n",
    "        sfm_dir, images_base, sfm_pairs, features, matches, image_list=image_list\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nReconstruction completed!\")\n",
    "    print(f\"Number of registered images: {len(model.images)}\")\n",
    "    print(f\"Number of 3D points: {len(model.points3D)}\")\n",
    "    print(f\"Number of cameras: {len(model.cameras)}\")\n",
    "    \n",
    "    # Visualize the reconstruction\n",
    "    print(\"\\nVisualizing 3D reconstruction...\")\n",
    "    fig = viz_3d.init_figure()\n",
    "    viz_3d.plot_reconstruction(\n",
    "        fig, model, color=\"rgba(255,0,0,0.5)\", name=\"reconstruction\", points_rgb=True\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Export Camera Poses\n",
    "\n",
    "Extract camera poses for all reconstructed frames and export in various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_camera_poses(model, output_dir):\n",
    "    \"\"\"Export camera poses in multiple formats.\"\"\"\n",
    "    poses_dir = output_dir / \"poses\"\n",
    "    poses_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Collect camera poses\n",
    "    camera_poses = []\n",
    "    \n",
    "    for image_id, image in model.images.items():\n",
    "        # Get camera pose (world-to-camera transform)\n",
    "        cam_from_world = image.cam_from_world\n",
    "        \n",
    "        # Convert to camera-to-world (more intuitive)\n",
    "        world_from_cam = cam_from_world.inverse()\n",
    "        \n",
    "        # Extract rotation and translation\n",
    "        rotation_matrix = world_from_cam.rotation.matrix()\n",
    "        translation = world_from_cam.translation\n",
    "        \n",
    "        # Convert rotation matrix to quaternion (w, x, y, z)\n",
    "        quaternion = world_from_cam.rotation.quaternion()  # [w, x, y, z]\n",
    "        \n",
    "        pose_data = {\n",
    "            'image_id': image_id,\n",
    "            'image_name': image.name,\n",
    "            'camera_id': image.camera_id,\n",
    "            'translation': translation.tolist(),\n",
    "            'rotation_matrix': rotation_matrix.tolist(),\n",
    "            'quaternion': quaternion.tolist(),  # [w, x, y, z]\n",
    "            'num_points3D': len(image.points3D_ids),\n",
    "        }\n",
    "        \n",
    "        camera_poses.append(pose_data)\n",
    "    \n",
    "    # Sort by image name for consistent ordering\n",
    "    camera_poses.sort(key=lambda x: x['image_name'])\n",
    "    \n",
    "    # Export as JSON\n",
    "    json_file = poses_dir / \"camera_poses.json\"\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(camera_poses, f, indent=2)\n",
    "    print(f\"Exported poses to JSON: {json_file}\")\n",
    "    \n",
    "    # Export in TUM format (timestamp tx ty tz qx qy qz qw)\n",
    "    tum_file = poses_dir / \"trajectory_tum.txt\"\n",
    "    with open(tum_file, 'w') as f:\n",
    "        f.write(\"# TUM trajectory format\\n\")\n",
    "        f.write(\"# timestamp tx ty tz qx qy qz qw\\n\")\n",
    "        for i, pose in enumerate(camera_poses):\n",
    "            tx, ty, tz = pose['translation']\n",
    "            qw, qx, qy, qz = pose['quaternion']\n",
    "            f.write(f\"{i:06d} {tx:.6f} {ty:.6f} {tz:.6f} {qx:.6f} {qy:.6f} {qz:.6f} {qw:.6f}\\n\")\n",
    "    print(f\"Exported poses in TUM format: {tum_file}\")\n",
    "    \n",
    "    # Export in COLMAP format (more detailed)\n",
    "    colmap_file = poses_dir / \"images_poses.txt\"\n",
    "    with open(colmap_file, 'w') as f:\n",
    "        f.write(\"# COLMAP image poses\\n\")\n",
    "        f.write(\"# IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME, POINTS2D\\n\")\n",
    "        for pose in camera_poses:\n",
    "            qw, qx, qy, qz = pose['quaternion']\n",
    "            tx, ty, tz = pose['translation']\n",
    "            f.write(f\"{pose['image_id']} {qw:.6f} {qx:.6f} {qy:.6f} {qz:.6f} \")\n",
    "            f.write(f\"{tx:.6f} {ty:.6f} {tz:.6f} {pose['camera_id']} {pose['image_name']}\\n\")\n",
    "    print(f\"Exported poses in COLMAP format: {colmap_file}\")\n",
    "    \n",
    "    return camera_poses\n",
    "\n",
    "if len(image_list) == 0 or 'model' not in locals():\n",
    "    print(\"Skipping pose export - no reconstruction available\")\n",
    "else:\n",
    "    print(\"Extracting and exporting camera poses...\")\n",
    "    camera_poses = export_camera_poses(model, OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"\\nExported {len(camera_poses)} camera poses\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nCamera poses summary:\")\n",
    "    for i, pose in enumerate(camera_poses[:5]):  # Show first 5\n",
    "        tx, ty, tz = pose['translation']\n",
    "        print(f\"  {pose['image_name']}: position=({tx:.3f}, {ty:.3f}, {tz:.3f})\")\n",
    "    \n",
    "    if len(camera_poses) > 5:\n",
    "        print(f\"  ... and {len(camera_poses) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Analysis\n",
    "\n",
    "Visualize camera poses and provide analysis of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(image_list) == 0 or 'model' not in locals():\n",
    "    print(\"Skipping visualization - no reconstruction available\")\n",
    "else:\n",
    "    # Visualize 2D features and matches\n",
    "    print(\"Visualizing feature matches...\")\n",
    "    if len(model.images) >= 2:\n",
    "        visualization.visualize_sfm_2d(model, images_base, color_by=\"visibility\", n=3)\n",
    "    \n",
    "    # Camera trajectory analysis\n",
    "    if 'camera_poses' in locals() and len(camera_poses) > 1:\n",
    "        print(\"\\nCamera trajectory analysis:\")\n",
    "        \n",
    "        # Calculate trajectory statistics\n",
    "        positions = np.array([pose['translation'] for pose in camera_poses])\n",
    "        \n",
    "        # Trajectory length\n",
    "        distances = np.sqrt(np.sum(np.diff(positions, axis=0)**2, axis=1))\n",
    "        total_distance = np.sum(distances)\n",
    "        \n",
    "        # Bounding box\n",
    "        min_pos = np.min(positions, axis=0)\n",
    "        max_pos = np.max(positions, axis=0)\n",
    "        bbox_size = max_pos - min_pos\n",
    "        \n",
    "        print(f\"  Total trajectory length: {total_distance:.3f} units\")\n",
    "        print(f\"  Average step size: {np.mean(distances):.3f} units\")\n",
    "        print(f\"  Scene bounding box: {bbox_size[0]:.3f} x {bbox_size[1]:.3f} x {bbox_size[2]:.3f}\")\n",
    "        print(f\"  Center position: ({np.mean(positions, axis=0)})\")\n",
    "        \n",
    "        # Plot camera trajectory in 3D\n",
    "        fig_traj = viz_3d.init_figure()\n",
    "        \n",
    "        # Plot camera positions as a trajectory\n",
    "        viz_3d.plot_points(fig_traj, positions, color=\"blue\", ps=3, name=\"camera_positions\")\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        import plotly.graph_objects as go\n",
    "        fig_traj.add_trace(go.Scatter3d(\n",
    "            x=positions[:, 0],\n",
    "            y=positions[:, 1], \n",
    "            z=positions[:, 2],\n",
    "            mode='lines',\n",
    "            name='trajectory',\n",
    "            line=dict(color='red', width=3)\n",
    "        ))\n",
    "        \n",
    "        fig_traj.update_layout(title=\"Camera Trajectory\")\n",
    "        fig_traj.show()\n",
    "    \n",
    "    print(\"\\nProcessing completed!\")\n",
    "    print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"  - 3D reconstruction: {OUTPUT_DIR / 'sfm'}\")\n",
    "    print(f\"  - Camera poses: {OUTPUT_DIR / 'poses'}\")\n",
    "    print(f\"  - Features and matches: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Output\n",
    "\n",
    "Summary of processing results and output file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"HLoC CAMERA POSE ESTIMATION PIPELINE - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(image_list) > 0 and 'model' in locals():\n",
    "    print(f\"✓ Successfully processed {len(image_list)} input images\")\n",
    "    print(f\"✓ Reconstructed {len(model.images)} camera poses\")\n",
    "    print(f\"✓ Generated {len(model.points3D)} 3D points\")\n",
    "    print(f\"✓ Used {len(model.cameras)} camera model(s)\")\n",
    "    \n",
    "    reconstruction_rate = len(model.images) / len(image_list) * 100\n",
    "    print(f\"✓ Reconstruction success rate: {reconstruction_rate:.1f}%\")\n",
    "    \n",
    "    print(\"\\nOutput files:\")\n",
    "    print(f\"  📁 Main output directory: {OUTPUT_DIR}\")\n",
    "    print(f\"  📄 Camera poses (JSON): poses/camera_poses.json\")\n",
    "    print(f\"  📄 Trajectory (TUM): poses/trajectory_tum.txt\")\n",
    "    print(f\"  📄 COLMAP poses: poses/images_poses.txt\")\n",
    "    print(f\"  📁 3D reconstruction: sfm/\")\n",
    "    print(f\"  📄 Features: features.h5\")\n",
    "    print(f\"  📄 Matches: matches.h5\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No valid input images found or processing failed\")\n",
    "    print(f\"   Please check that {INPUT_DIR} contains video files or images\")\n",
    "    print(\"   Supported video formats: .mp4, .avi, .mov, .mkv, .wmv, .flv, .webm\")\n",
    "    print(\"   Supported image formats: .jpg, .jpeg, .png, .bmp, .tiff, .tif\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Pipeline execution completed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
